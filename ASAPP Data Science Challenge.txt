ASAPP Data Science Challenge
============================

ASAPP builds state of the art Natural Language Processing and Machine Learning tools that empower human customer service representatives to become 10X more efficient than they are today. A key ingredient is our auto-suggestion server, which significantly speeds up the customer service representatives' responses.

I've included a .gif which demonstrates an early version of our auto-suggestion server - it should give you a good idea of what I'm talking about.


Your challenge is to design and implement a similar NLP/ML-based auto-suggestion server, using the sample chat histories in sample_conversations.json, and then prepare to talk through what the challenges would be in scaling it up and how you would tackle those challenges.

Take the time that you need, but fast is better than slow.

If we mutually agree to proceed then I will ask you to come in and continue work on this challenge alongside the rest of the team in our office.

Misc thoughts and recommendations before we go into details
-----------------------------------------------------------

- Use the programming languages and tools that you're most familiar with.
- Use open source libraries instead of reinventing the wheel. (For example, we use Theano, Pandas, NLTK, Megam, Torch, CherryPy, Werkzeug etc...)
- Use version control. It's a plus if your results come with e.g a git commit history.
- We rely on tests to move fast and break nothing. I recommend that you do as well.
- Have fun! If you don't think this project sounds like fun, then working at ASAPP may not be your cup of tea :)


Goals
-----

1: Offline data processing

    · Write a function that reads the sample_conversations.json file, processes the data, and creates whataver data models you need to generate realtime auto-suggestions.
    · It's fine if this function takes a very long time to run. However, a week is probably a bit too long :)
    · Extra credit: Make the processed data model serializable, so that it can be saved to disk once it's been constructed

2: Realtime autosuggest

    · Write a function that uses the data model from step 1 and takes a text input prefix and generates sentence completions. Here are some examples of what it could look like:
    
        generate_suggestions('how ca') -> ['How can I help you today?']
        generate_suggestions('what is y') -> ['What is your account number?', 'What is your address?', 'What is your order number?']
        generate_suggestions('when w' -> ['When was the last time', 'When was the last time you changed your password?', 'When was the last time you rebooted your router?'])
    
    · This function should be *fast*! It would be called on every keystroke, so thousands of times per second per server.
    · The input of the function should be a partial message input, and the output should be a small list of suggestions. Imagine using the product in the .gif yourself, and try to generate outputs that you believe would be genuinely useful for a customer service representative.

3: Autosuggest server

    · Wrap the realtime autosuggest engine in an HTTP server, and return suggestions as JSON, e.g
    
        # curl http://localhost:13000/autosuggest?q=When+did
        {"Suggestions": ["When did the", "When did the problem begin", "When did the problem"]}


Follow-up questions
-------------------

Please take the time to write answers to these questions along with your solution. Think through them as thoroughly as you can. Our goal will be to get a sense of how comprehensively you understand and think about the type of problems we face.

It's fine if you don't have concrete answers to all of them; I will still want to hear your thought process. Sometimes asking the right questions is even more important than finding the answer!

If we mutually decide to continue the conversation, then the next step will be to discuss your answers together over the phone.

- How would you evaluate your autosuggest server? If you made another version, how would you compare the two to decide which is better?
- One way to improve the autosuggest server is to give topic-specific suggestions. How would you design an auto-categorization server? It should take a list of messages and return a TopicId. (Assume that every conversation in the training set has a TopicId).
- How would you evaluate if your auto-categorization server is good?
- Processing hundreds of millions of conversations for your autosuggest and auto-categorize models could take a very long time. How could you distribute the processing across multiple machines?

